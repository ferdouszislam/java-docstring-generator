{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOnQ1dCIxvXCCWTQYJooXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdouszislam/java-docstring-generator/blob/main/javadoc_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets evaluate accelerate rouge_score"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uX4DwgQq9-UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ1GuXKzZqUi"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (AutoTokenizer, DataCollatorForSeq2Seq,\n",
        "                          AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments,\n",
        "                          Seq2SeqTrainer, pipeline)\n",
        "import evaluate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "javadoc_ds = load_dataset(\n",
        "    'Shuu12121/java-treesitter-dedupe_doc-filtered-dataset',\n",
        "    split='train[:100]')\n",
        "\n",
        "sample = javadoc_ds[0]\n",
        "print(f\"features: {sample.keys()}\")\n",
        "\n",
        "# print(f\"code:\\n {sample['code']}\")\n",
        "# print(f\"docstring:\\n {sample['docstring']}\")"
      ],
      "metadata": {
        "id": "wev18U5AaT1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "javadoc_ds = javadoc_ds.train_test_split(test_size=0.2)\n",
        "print(javadoc_ds)"
      ],
      "metadata": {
        "id": "qLk8xHRUb9gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google-t5/t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "rCfA88A3xNOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize dataset"
      ],
      "metadata": {
        "id": "Pb91O22FDWor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PREFIX = \"Generate JavaDoc for the function: \"\n",
        "\n",
        "def preprocess_ds(ds):\n",
        "  inputs = [INPUT_PREFIX + doc for doc in ds[\"code\"]]\n",
        "  model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "  labels = tokenizer(text_target=ds[\"docstring\"], max_length=256,\n",
        "                      truncation=True)\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs"
      ],
      "metadata": {
        "id": "53-CM7SA_nbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_javadoc_ds = javadoc_ds.map(preprocess_ds, batched=True)"
      ],
      "metadata": {
        "id": "mAT48oI-A-Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
      ],
      "metadata": {
        "id": "g418iA5h8gDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup evaluation process"
      ],
      "metadata": {
        "id": "dPDHWpGbDLAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BLEU metric\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # BLEU expects list of references for each prediction\n",
        "    references = [[label] for label in decoded_labels]\n",
        "\n",
        "    # Compute BLEU score\n",
        "    result = bleu.compute(predictions=decoded_preds, references=references)\n",
        "\n",
        "    # Extract the scalar BLEU score\n",
        "    bleu_score = result[\"bleu\"]\n",
        "\n",
        "    # Add generation length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    gen_len = np.mean(prediction_lens)\n",
        "\n",
        "    return {\"eval_bleu\": round(bleu_score, 4), \"eval_gen_len\": round(gen_len, 4)}"
      ],
      "metadata": {
        "id": "Zku3hZ1R9coX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup model"
      ],
      "metadata": {
        "id": "ccB3LkldDdpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "8CW4MiGp-wlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "hx3iyhbaDgaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_STORE_PATH = \"./demis_java_docstr_generator\"\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=MODEL_STORE_PATH,\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,                   # Increase (faster convergence)\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,                   # Keep fewer checkpoints\n",
        "    num_train_epochs=4,                   # Reduce epochs\n",
        "    predict_with_generate=True,\n",
        "    fp16=True, #change to bf16=True for XPU\n",
        "    report_to=\"none\" # Disable wandb reporting\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_javadoc_ds[\"train\"],\n",
        "    eval_dataset=tokenized_javadoc_ds[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "2UwAIr-z_tzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print evaluation scores"
      ],
      "metadata": {
        "id": "m1DRqCbGDizl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "\n",
        "def print_results(results, model_name):\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"BLEU Score: {results['eval_bleu']:.4f}\")\n",
        "    print(f\"Gen Length: {results['eval_gen_len']:.1f}\")\n",
        "\n",
        "print_results(results, \"T5-Small Java Docstring\")"
      ],
      "metadata": {
        "id": "4nrGZQtZAtQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "cFfKU3SYDwvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(MODEL_STORE_PATH)"
      ],
      "metadata": {
        "id": "_CArnzKMDyPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "iTX0Xit3ESVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_sample = \"\"\"\n",
        "public boolean isPalindrome(String str) {\n",
        "    // Remove spaces and convert to lowercase for case-insensitive comparison\n",
        "    String cleanedStr = str.replaceAll(\"\\\\s+\", \"\").toLowerCase();\n",
        "\n",
        "    int left = 0;\n",
        "    int right = cleanedStr.length() - 1;\n",
        "\n",
        "    while (left < right) {\n",
        "        if (cleanedStr.charAt(left) != cleanedStr.charAt(right)) {\n",
        "            return false;\n",
        "        }\n",
        "        left++;\n",
        "        right--;\n",
        "    }\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\"\"\"\n",
        "code_sample = INPUT_PREFIX + code_sample"
      ],
      "metadata": {
        "id": "VYDZ8Yk6ETZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference via pipeline()"
      ],
      "metadata": {
        "id": "wle3iuSkD7DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demis_java_docstr_generator = pipeline(\"summarization\",\n",
        "                                       model=MODEL_STORE_PATH,\n",
        "                                       tokenizer=MODEL_STORE_PATH)\n",
        "demis_java_docstr_generator(code_sample)"
      ],
      "metadata": {
        "id": "XsIfLFeXD9bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Inference"
      ],
      "metadata": {
        "id": "OPAX2Tz_E_EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_STORE_PATH)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_STORE_PATH)\n",
        "inputs = tokenizer(code_sample, return_tensors=\"pt\").input_ids\n",
        "outputs = model.generate(inputs, max_new_tokens=100, do_sample=False)\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "_c5qoduZFAwn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}